---
title: "BulkWriterã‚’ä½¿ã† | Cloud"
slug: /use-bulkwriter
sidebar_label: "BulkWriterã‚’ä½¿ã†"
beta: FALSE
notebook: FALSE
description: "ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒè¦ä»¶ã‚’æº€ãŸã—ã¦ã„ãªã„å ´åˆã¯ã€pymilvusã¨Milvusã®Java SDKã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹BulkWriterã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ | Cloud"
type: origin
token: HckPwGc3IiSJM7kYS8Xco3RYnfg
sidebar_position: 1
keywords: 
  - zilliz
  - vector database
  - cloud
  - data import
  - bulk writer
  - AI Agent
  - semantic search
  - Anomaly Detection
  - sentence transformers

---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# BulkWriterã‚’ä½¿ã†

ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒè¦ä»¶ã‚’æº€ãŸã—ã¦ã„ãªã„å ´åˆã¯ã€pymilvusã¨Milvusã®Java SDKã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹**BulkWriter**ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## æ¦‚è¦ã«ã¤ã„ã¦{#overview}

**BulkWriter**ã¯ã€Zilliz Cloudã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã€Milvus SDKã®**BulkInsert**APIã€ã¾ãŸã¯RESTfulãƒ•ãƒ¬ãƒ¼ãƒãƒ¼ã®**Import** APIãªã©ã€ã•ã¾ã–ã¾ãªæ–¹æ³•ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«é©ã—ãŸå½¢å¼ã«ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™ã€‚2ç¨®é¡ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã‚’æä¾›ã—ã¦ã„ã¾ã™

- **LocalBulkWriter**:æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿å–ã‚Šã€ä½¿ã„ã‚„ã™ã„å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚

- **RemoteBulkWriter**: Local BulkWriterã¨åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—**ã¾**ã™ãŒã€å¤‰æ›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ãŸãƒªãƒ¢ãƒ¼ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒã‚±ãƒƒãƒˆã«è»¢é€ã—ã¾ã™ã€‚

## æ‰‹ç¶šã{#procedure}

### ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šã™ã‚‹{#set-up-dependencies}

<Tabs groupId="code"defaultValue='python'value={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

<TabItem value='python'>

ã‚·ã‚§ãƒ«ã§æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€pymilvusã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã‹ã€pymilvusã‚’æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚

```bash
pip install --upgrade pymilvus
```

</TabItem>

<TabItem value='java'>

Apache Mavenã®å ´åˆã€**pom. xml**ã®ä¾å­˜é–¢ä¿‚ã«ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„:

```java
<dependency>
  <groupId>io.milvus</groupId>
  <artifactId>milvus-sdk-java</artifactId>
  <version>2.4.8</version>
</dependency>
```

- Gradle/Grailsã®å ´åˆã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```shell
compile 'io.milvus:milvus-sdk-java:2.4.8'
```

</TabItem>

</Tabs>

### ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒ¼ãƒã‚’è¨­å®šã™ã‚‹{#set-up-a-collection-schema}

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¹ã‚­ãƒ¼ãƒã‚’æ±ºå®šã—ã¾ã™ã€‚ã“ã‚Œã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰å«ã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã™ã¹ã¦ã®å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿å‹ã‚’æŒã¤ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚­ãƒ¼ãƒã¯ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è‡ªå‹•çš„ãªã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã‚’ç„¡åŠ¹ã«ã—ã€å‹•çš„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
from pymilvus import MilvusClient, DataType

# You need to work out a collection schema out of your dataset.
schema = MilvusClient.create_schema(
    auto_id=False,
    enable_dynamic_field=True
)

DIM = 512

schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True),
schema.add_field(field_name="bool", datatype=DataType.BOOL),
schema.add_field(field_name="int8", datatype=DataType.INT8),
schema.add_field(field_name="int16", datatype=DataType.INT16),
schema.add_field(field_name="int32", datatype=DataType.INT32),
schema.add_field(field_name="int64", datatype=DataType.INT64),
schema.add_field(field_name="float", datatype=DataType.FLOAT),
schema.add_field(field_name="double", datatype=DataType.DOUBLE),
schema.add_field(field_name="varchar", datatype=DataType.VARCHAR, max_length=512),
schema.add_field(field_name="json", datatype=DataType.JSON),
schema.add_field(field_name="array_str", datatype=DataType.ARRAY, max_capacity=100, element_type=DataType.VARCHAR, max_length=128)
schema.add_field(field_name="array_int", datatype=DataType.ARRAY, max_capacity=100, element_type=DataType.INT64)
schema.add_field(field_name="float_vector", datatype=DataType.FLOAT_VECTOR, dim=DIM),
schema.add_field(field_name="binary_vector", datatype=DataType.BINARY_VECTOR, dim=DIM),
schema.add_field(field_name="float16_vector", datatype=DataType.FLOAT16_VECTOR, dim=DIM),
# schema.add_field(field_name="bfloat16_vector", datatype=DataType.BFLOAT16_VECTOR, dim=DIM),
schema.add_field(field_name="sparse_vector", datatype=DataType.SPARSE_FLOAT_VECTOR)

schema.verify()
```

</TabItem>

<TabItem value='java'>

```java
import io.milvus.param.collection.CollectionSchemaParam;
import io.milvus.param.collection.FieldType;
import io.milvus.grpc.DataType;

private static CreateCollectionReq.CollectionSchema createSchema() {
    CreateCollectionReq.CollectionSchema schema = CreateCollectionReq.CollectionSchema.builder()
        .enableDynamicField(true)
        .build();
    schema.addField(AddFieldReq.builder()
            .fieldName("id")
            .dataType(io.milvus.v2.common.DataType.Int64)
            .isPrimaryKey(Boolean.TRUE)
            .autoID(false)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("bool")
            .dataType(DataType.Bool)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int8")
            .dataType(DataType.Int8)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int16")
            .dataType(DataType.Int16)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int32")
            .dataType(DataType.Int32)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int64")
            .dataType(DataType.Int64)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float")
            .dataType(DataType.Float)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("double")
            .dataType(DataType.Double)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("varchar")
            .dataType(DataType.VarChar)
            .maxLength(512)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("json")
            .dataType(io.milvus.v2.common.DataType.JSON)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("array_int")
            .dataType(io.milvus.v2.common.DataType.Array)
            .maxCapacity(100)
            .elementType(io.milvus.v2.common.DataType.Int64)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("array_str")
            .dataType(io.milvus.v2.common.DataType.Array)
            .maxCapacity(100)
            .elementType(io.milvus.v2.common.DataType.VarChar)
            .maxLength(128)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float_vector")
            .dataType(io.milvus.v2.common.DataType.FloatVector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("binary_vector")
            .dataType(io.milvus.v2.common.DataType.BinaryVector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float16_vector")
            .dataType(io.milvus.v2.common.DataType.Float16Vector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("sparse_vector")
            .dataType(io.milvus.v2.common.DataType.SparseFloatVector)
            .build());
    
    return schema;
}

private static byte[] genBinaryVector() {
    Random ran = new Random();
    int byteCount = DIM / 8;
    ByteBuffer vector = ByteBuffer.allocate(byteCount);
    for (int i = 0; i < byteCount; ++i) {
        vector.put((byte) ran.nextInt(Byte.MAX_VALUE));
    }
    return vector.array();
}
```

</TabItem>
</Tabs>

### BulkWriterã‚’ä½œæˆã™ã‚‹{#create-a-bulkwriter}

BulkWriterã«ã¯**2ã¤**ã®ã‚¿ã‚¤ãƒ—ãŒã‚ã‚Šã¾ã™ã€‚

- **LocalBulkWriterã®è¨­å®š**

    Local BulkWriter**ã¯**ã€ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰è¡Œã‚’è¿½åŠ ã—ã€æŒ‡å®šã—ãŸå½¢å¼ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ã€‚

    <Tabs groupId="code"defaultValue='python'value={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

    <TabItem value='python'>

    ```python
    from pymilvus.bulk_writer import LocalBulkWriter, BulkFileType
    # Use `from pymilvus import LocalBulkWriter, BulkFileType` 
    # when you use pymilvus earlier than 2.4.2 
    
    writer = LocalBulkWriter(
        schema=schema,
        local_path='.',
        chunk_size=1024 * 1024 * 1024,
        file_type=BulkFileType.PARQUET
    )
    ```

    LocalBulkWriterã‚’ä½œæˆã™ã‚‹ã¨ã**ã¯**ã€æ¬¡ã®ã‚ˆã†ã«ã—ã¾ã™ã€‚

    - ä½œæˆã—ãŸã‚¹ã‚­ãƒ¼ãƒã‚’schemaã§**å‚ç…§**ã€‚

    - å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«**local_path**ã‚’è¨­å®šã—ã¾ã™ã€‚

    - file_type**ã«å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—**ã‚’è¨­å®šã—ã¾ã™ã€‚

    - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¤šæ•°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€**sement_size**ã‚’é©åˆ‡ãªå€¤ã«è¨­å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®è©³ç´°ã¯ã€S DKãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã®Local**BulkWriter**ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

    <Admonition type="info" icon="ğŸ“˜" title="ãƒãƒ¼ãƒˆ">

    <p>Local BulkWriterã§ç”Ÿæˆã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿<strong>ãŒ</strong>Zilliz Cloudã«ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã™ã€‚</p>
    <p>ä»–ã®ç¨®é¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦ã¯ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹å‰ã«ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨åŒã˜ã‚¯ãƒ©ã‚¦ãƒ‰ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒã‚±ãƒƒãƒˆã®1ã¤ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚</p>

    </Admonition>

    </TabItem>

    <TabItem value='java'>

    ```java
    import io.milvus.bulkwriter.LocalBulkWriter;
    import io.milvus.bulkwriter.LocalBulkWriterParam;
    import io.milvus.bulkwriter.common.clientenum.BulkFileType;
    
    LocalBulkWriterParam localBulkWriterParam = LocalBulkWriterParam.newBuilder()
        .withCollectionSchema(schema)
        .withLocalPath(".")
        .withChunkSize(1024 * 1024 * 1024)
        .withFileType(BulkFileType.PARQUET)
        .build();
    
    LocalBulkWriter localBulkWriter = new LocalBulkWriter(localBulkWriterParam);
    ```

    LocalBulkWriterã‚’ä½œæˆã™ã‚‹ã¨ã**ã¯**ã€æ¬¡ã®ã‚ˆã†ã«ã—ã¾ã™ã€‚

    - ä½œæˆã—ãŸã‚¹ã‚­ãƒ¼ãƒã‚’**withCollectionSchema()**ã§å‚ç…§ã—ã¾ã™ã€‚

    - withLocal Path**()**ã§å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã™ã€‚

    - withFileType()ã§å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’BulkFileType.**PARQUET**ã«**è¨­å®šã—ã¾ã™**ã€‚

    - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¤šæ•°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€**withChunkSize()**ã§é©åˆ‡ãªå€¤ã‚’è¨­å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

    <Admonition type="info" icon="ğŸ“˜" title="ãƒãƒ¼ãƒˆ">

    <p>Java SDKã®BulkWriterã¯ç¾åœ¨ã€å”¯ä¸€ã®æœ‰åŠ¹ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã¨ã—ã¦Apache Parquetã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚</p>

    </Admonition>

    </TabItem>

    </Tabs>

- **RemoteBulkWriter**

    RemoteBulkWriterã¯ã€è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ä»£ã‚ã‚Šã«ã€**ãƒªãƒ¢ãƒ¼ãƒˆ**ãƒã‚±ãƒƒãƒˆã«ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ã€‚ãã®ãŸã‚ã€RemoteBulkWriterã‚’ä½œæˆã™ã‚‹å‰ã«ã€**ConnectParam**ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾**ã™**ã€‚

    <Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
    <TabItem value='python'>

    <Tabs groupId="python" defaultValue='python' values={[{"label":"AWS S3/GCS","value":"python"},{"label":"Azure Blog Storage","value":"python_1"}]}>
    <TabItem value='python'>

    ```python
    
    from pymilvus.bulk_writer import RemoteBulkWriter
    # Use `from pymilvus import RemoteBulkWriter` 
    # when you use pymilvus earlier than 2.4.2 
    
    # Third-party constants
    ACCESS_KEY="bucket-ak"
    SECRET_KEY="bucket-sk"
    BUCKET_NAME="a-bucket"
    REGION_NAME="region-name"
    
    # Connections parameters to access the remote bucket
    conn = RemoteBulkWriter.S3ConnectParam(
        endpoint="s3.amazonaws.com", # use 'storage.googleapis.com' for Google Cloud Storage
        access_key=ACCESS_KEY,
        secret_key=SECRET_KEY,
        bucket_name=BUCKET_NAME,
        secure=True,
        region=REGION_NAME
    )
    
    from pymilvus.bulk_writer import BulkFileType
    # Use `from pymilvus import BulkFileType` 
    # when you use pymilvus earlier than 2.4.2 
    
    writer = RemoteBulkWriter(
        schema=schema,
        remote_path="/",
        connect_param=conn,
        file_type=BulkFileType.PARQUET
    )
    
    print('bulk writer created.')
    
    ```

    </TabItem>
    <TabItem value='python_1'>

    ```python
    from pymilvus.bulk_writer import RemoteBulkWriter
    # Use `from pymilvus import RemoteBulkWriter` 
    # when you use pymilvus earlier than 2.4.2 
    
    # Third-party constants
    AZURE_CONNECT_STRING = ""
    
    conn = RemoteBulkWriter.AzureConnectParam(
        conn_str=AZURE_CONNECT_STRING,
        container_name=BUCKET_NAME
    )
    
    # or
    
    # Third-party constants
    AZURE_ACCOUNT_URL = ""
    AZURE_CREDENTIAL = ""
    
    conn = RemoteBulkWriter.AzureConnectParam(
        account_url=AZURE_ACCOUNT_URL,
        credential=AZURE_CREDENTIAL,
        container_name=BUCKET_NAME
    )
    ```

    </TabItem>
    </Tabs>
    </TabItem>

    <TabItem value='java'>

    <Tabs groupId="java" defaultValue='java' values={[{"label":"AWS S3/GCS","value":"java"},{"label":"Microsoft Azure","value":"java_1"}]}>
    <TabItem value='java'>

    ```java
    
    import io.milvus.bulkwriter.connect.S3ConnectParam;
    import io.milvus.bulkwriter.connect.StorageConnectParam;
    
    // Configs for remote bucket
    String ACCESS_KEY = "";
    String SECRET_KEY = "";
    String BUCKET_NAME = "";
    
    // Enumeration can refer to CloudStorage
    String CLOUD_NAME = "";
    String REGION_NAME = "";
    
    // Create a remote bucket writer.
    StorageConnectParam storageConnectParam = S3ConnectParam.newBuilder()
            .withEndpoint("storage.googleapis.com")
            .withBucketName(BUCKET_NAME)
            .withAccessKey(ACCESS_KEY)
            .withSecretKey(SECRET_KEY)
            .withCloudName(CLOUD_NAME)
            .withRegion(REGION_NAME)
            .build();
    
    ```

    </TabItem>
    <TabItem value='java_1'>

    ```java
    import io.milvus.bulkwriter.connect.AzureConnectParam;
    import io.milvus.bulkwriter.connect.StorageConnectParam;
    
    String AZURE_CONNECT_STRING = ""
    String AZURE_CONTAINER = ""
    
    StorageConnectParam storageConnectParam = AzureConnectParam.newBuilder()
            .withConnStr(AZURE_CONNECT_STRING)
            .withContainerName(AZURE_CONTAINER)
            .build()
    ```

    </TabItem>
    </Tabs>
    </TabItem>
    </Tabs>

    æ¥ç¶šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®æº–å‚™ãŒã§ããŸã‚‰ã€RemoteBulkWriterã§æ¬¡ã®ã‚ˆã†ã«å‚ç…§ã§ã**ã¾**ã™ã€‚

    <Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
    <TabItem value='python'>

    ```python
    from pymilvus.bulk_writer import RemoteBulkWriter
    # Use `from pymilvus import RemoteBulkWriter` 
    # when you use pymilvus earlier than 2.4.2 
    
    writer = RemoteBulkWriter(
        schema=schema,
        remote_path="/",
        connect_param=conn,
        file_type=BulkFileType.PARQUET
    )
    ```

    </TabItem>

    <TabItem value='java'>

    ```java
    import io.milvus.bulkwriter.RemoteBulkWriter;
    import io.milvus.bulkwriter.RemoteBulkWriterParam;
    import io.milvus.bulkwriter.common.clientenum.BulkFileType;
    
    RemoteBulkWriterParam remoteBulkWriterParam = RemoteBulkWriterParam.newBuilder()
            .withCollectionSchema(schema)
            .withRemotePath("/")
            .withChunkSize(1024 * 1024 * 1024)
            .withConnectParam(storageConnectParam)
            .withFileType(BulkFileType.PARQUET)
            .build();
            
    RemoteBulkWriter remoteBulkWriter = new RemoteBulkWriter(remoteBulkWriterParam);
    ```

    </TabItem>
    </Tabs>

    RemoteBulkWriterã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€**Local BulkWriter**ã¨ã»ã¨ã‚“ã©åŒã˜ã§ã™ãŒã€**connect_paramã¯ç•°ãªã‚Šã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã«ã¤ã„ã¦ã¯ã€S DKãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã®RemoteBulkWriter**ã¨**ConnectParam**ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### æ›¸ãå§‹ã‚ã‚‹{#start-writing}

<Tabs groupId="code"defaultValue='python'value={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

<TabItem value='python'>

BulkWriterã«ã¯**2ã¤**ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚**append_row()**ã¯ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ­ãƒ¼ã‚’è¿½åŠ ã—ã€**commit()**ã¯è¿½åŠ ã•ã‚ŒãŸãƒ­ãƒ¼ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒªãƒ¢ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆã«ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ã€‚

ãƒ‡ãƒ¢ç›®çš„ã§ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™ã€‚

```python
import random, string, json
import numpy as np
import tensorflow as tf

def generate_random_str(length=5):
    letters = string.ascii_uppercase
    digits = string.digits
    
    return ''.join(random.choices(letters + digits, k=length))

# optional input for binary vector:
# 1. list of int such as [1, 0, 1, 1, 0, 0, 1, 0]
# 2. numpy array of uint8
def gen_binary_vector(to_numpy_arr):
    raw_vector = [random.randint(0, 1) for i in range(DIM)]
    if to_numpy_arr:
        return np.packbits(raw_vector, axis=-1)
    return raw_vector

# optional input for float vector:
# 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# 2. numpy array of float32
def gen_float_vector(to_numpy_arr):
    raw_vector = [random.random() for _ in range(DIM)]
    if to_numpy_arr:
        return np.array(raw_vector, dtype="float32")
    return raw_vector

# # optional input for bfloat16 vector:
# # 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# # 2. numpy array of bfloat16
# def gen_bf16_vector(to_numpy_arr):
#     raw_vector = [random.random() for _ in range(DIM)]
#     if to_numpy_arr:
#         return tf.cast(raw_vector, dtype=tf.bfloat16).numpy()
#     return raw_vector

# optional input for float16 vector:
# 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# 2. numpy array of float16
def gen_fp16_vector(to_numpy_arr):
    raw_vector = [random.random() for _ in range(DIM)]
    if to_numpy_arr:
        return np.array(raw_vector, dtype=np.float16)
    return raw_vector

# optional input for sparse vector:
# only accepts dict like {2: 13.23, 45: 0.54} or {"indices": [1, 2], "values": [0.1, 0.2]}
# note: no need to sort the keys
def gen_sparse_vector(pair_dict: bool):
    raw_vector = {}
    dim = random.randint(2, 20)
    if pair_dict:
        raw_vector["indices"] = [i for i in range(dim)]
        raw_vector["values"] = [random.random() for _ in range(dim)]
    else:
        for i in range(dim):
            raw_vector[i] = random.random()
    return raw_vector

for i in range(10000):
    writer.append_row({
        "id": np.int64(i),
        "bool": True if i % 3 == 0 else False,
        "int8": np.int8(i%128),
        "int16": np.int16(i%1000),
        "int32": np.int32(i%100000),
        "int64": np.int64(i),
        "float": np.float32(i/3),
        "double": np.float64(i/7),
        "varchar": f"varchar_{i}",
        "json": json.dumps({"dummy": i, "ok": f"name_{i}"}),
        "array_str": np.array([f"str_{k}" for k in range(5)], np.dtype("str")),
        "array_int": np.array([k for k in range(10)], np.dtype("int64")),
        "float_vector": gen_float_vector(True),
        "binary_vector": gen_binary_vector(True),
        "float16_vector": gen_fp16_vector(True),
        # "bfloat16_vector": gen_bf16_vector(True),
        "sparse_vector": gen_sparse_vector(True),
        f"dynamic_{i}": i,
    })
    if (i+1)%1000 == 0:
        writer.commit()
        print('committed')
```

</TabItem>

<TabItem value='java'>

BulkWriterã«ã¯**2ã¤**ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚**appendRow()**ã¯ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ­ãƒ¼ã‚’è¿½åŠ ã—ã€**commit()**ã¯è¿½åŠ ã•ã‚ŒãŸãƒ­ãƒ¼ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒªãƒ¢ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆã«ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ã€‚

ãƒ‡ãƒ¢ç›®çš„ã§ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™ã€‚

<Tabs groupId="java" defaultValue='java' values={[{"label":"Main","value":"java"},{"label":"Random data generators","value":"java_1"}]}>
<TabItem value='java'>

```java

import com.google.gson.Gson;
import com.google.gson.JsonObject;
import io.milvus.common.utils.Float16Utils;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.TimeUnit;

private static List<List<String>> uploadData() throws Exception {
    CreateCollectionReq.CollectionSchema collectionSchema = createSchema();
    try (RemoteBulkWriter remoteBulkWriter = createRemoteBulkWriter(collectionSchema)) {
        for (int i = 0; i < 10000; ++i) {
            JsonObject rowObject = new JsonObject();

            rowObject.addProperty("id", i);
            rowObject.addProperty("bool", i % 3 == 0);
            rowObject.addProperty("int8", i % 128);
            rowObject.addProperty("int16", i % 1000);
            rowObject.addProperty("int32", i % 100000);
            rowObject.addProperty("int64", i);
            rowObject.addProperty("float", i / 3);
            rowObject.addProperty("double", i / 7);
            rowObject.addProperty("varchar", "varchar_" + i);
            rowObject.addProperty("json", String.format("{\"dummy\": %s, \"ok\": \"name_%s\"}", i, i));
            rowObject.add("array_str", GSON_INSTANCE.toJsonTree(genStringArray(5)));
            rowObject.add("array_int", GSON_INSTANCE.toJsonTree(genIntArray(10)));
            rowObject.add("float_vector", GSON_INSTANCE.toJsonTree(genFloatVector()));
            rowObject.add("binary_vector", GSON_INSTANCE.toJsonTree(genBinaryVector()));
            rowObject.add("float16_vector", GSON_INSTANCE.toJsonTree(genFloat16Vector()));
            rowObject.add("sparse_vector", GSON_INSTANCE.toJsonTree(genSparseVector()));
            rowObject.addProperty("dynamic", "dynamic_" + i);

            remoteBulkWriter.appendRow(rowObject);

            if ((i+1)%1000 == 0) {
                remoteBulkWriter.commit(false);
            }
        }

        List<List<String>> batchFiles = remoteBulkWriter.getBatchFiles();
        System.out.println(batchFiles);
        return batchFiles;
    } catch (Exception e) {
        throw e;
    }
}

```

</TabItem>
<TabItem value='java_1'>

```java
private static byte[] genBinaryVector() {
    Random ran = new Random();
    int byteCount = DIM / 8;
    ByteBuffer vector = ByteBuffer.allocate(byteCount);
    for (int i = 0; i < byteCount; ++i) {
        vector.put((byte) ran.nextInt(Byte.MAX_VALUE));
    }
    return vector.array();
}

private static List<Float> genFloatVector() {
    Random ran = new Random();
    List<Float> vector = new ArrayList<>();
    for (int i = 0; i < DIM; ++i) {
        vector.add(ran.nextFloat());
    }
    return vector;
}

private static byte[] genFloat16Vector() {
    List<Float> originalVector = genFloatVector();
    return Float16Utils.f32VectorToFp16Buffer(originalVector).array();
}

private static SortedMap<Long, Float> genSparseVector() {
    Random ran = new Random();
    SortedMap<Long, Float> sparse = new TreeMap<>();
    int dim = ran.nextInt(18) + 2; // [2, 20)
    for (int i = 0; i < dim; ++i) {
        sparse.put((long)ran.nextInt(1000000), ran.nextFloat());
    }
    return sparse;
}

private static List<String> genStringArray(int length) {
    List<String> arr = new ArrayList<>();
    for (int i = 0; i < length; i++) {
        arr.add("str_" + i);
    }
    return arr;
}

private static List<Long> genIntArray(int length) {
    List<Long> arr = new ArrayList<>();
    for (long i = 0; i < length; i++) {
        arr.add(i);
    }
    return arr;
}
```

</TabItem>
</Tabs>

<Admonition type="info" icon="ğŸ“˜" title="ãƒãƒ¼ãƒˆ">

<p>ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§ã¯ã€<code>vector</code>ã¨<code>scalar_1</code>ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã¯ã€ãã‚Œãã‚Œ<code>generateFloatVectors()</code>ã¨<code>generateString()</code>ã¨ã„ã†2ã¤ã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆé–¢æ•°ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€<strong>Random data generator</strong>ã‚¿ãƒ–ã®ã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>

</Admonition>

</TabItem>

</Tabs>

## å‹•çš„ã‚¹ã‚­ãƒ¼ãƒã®ã‚µãƒãƒ¼ãƒˆ{#dynamic-schema-support}

[å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³](./use-bulkwriter#set-up-a-collection-schema)ã§ã¯ã€ãƒ©ã‚¤ã‚¿ãƒ¼ã§å‹•çš„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨±å¯ã—ã€è¡Œã‚’è¿½åŠ ã™ã‚‹ã¨ãã«æœªå®šç¾©ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚¹ã‚­ãƒ¼ãƒã‚’å‚ç…§ã—ã¾ã—ãŸã€‚

ãƒ‡ãƒ¢ç›®çš„ã§ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
import random
import string

def generate_random_string(length=5):
    letters = string.ascii_uppercase
    digits = string.digits
    
    return ''.join(random.choices(letters + digits, k=length))

for i in range(10000):
    writer.append_row({
        "id": i, 
        "vector":[random.uniform(-1, 1) for _ in range(768)],
        "dynamic_field_1": random.choice([True, False]),
        "dynamic_field_2": random.randint(0, 100)
    })
    
writer.commit()
```

</TabItem>

<TabItem value='java'>

<Tabs groupId="java" defaultValue='java' values={[{"label":"Main","value":"java"},{"label":"Random data generators","value":"java_1"}]}>
<TabItem value='java'>

```java

import java.util.Random

List<JSONObject> data = new ArrayList<>();

for (int i=0; i<10000; i++) {
    Random rand = new Random();
    JSONObject row = new JSONObject();
    
    row.put("id", Long.valueOf(i));
    row.put("vector", generateFloatVectors(768);
    row.put("dynamic_field_1", rand.nextBoolean());
    row.put("dynamic_field_2", rand.nextInt(100));
    remoteBulkWriter.appendRow(row);
}

remoteBulkWriter.commit()

```

</TabItem>
<TabItem value='java_1'>

```java
private static List<float> generateFloatVectors(int dimension) {
    List<float> vector = new ArrayList();
    
    for (int i=0; i< dimension; i++) {
        Random rand = new Random();
        vector.add(rand.nextFloat())
    }
    
    return vector
}

private static String generateString(length) {
    byte[] array = new byte[length];
    new Random().nextBytes(array);
    
    return new String(array, Charset.forName("UTF-8"));
}
```

</TabItem>
</Tabs>
</TabItem>
</Tabs>

## çµæœã‚’ç¢ºèªã™ã‚‹{#verify-the-result}

çµæœã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ãƒ©ã‚¤ã‚¿ãƒ¼ã®**data_path**ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å°åˆ·ã—ã¦ã€å®Ÿéš›ã®å‡ºåŠ›ãƒ‘ã‚¹ã‚’å–å¾—ã§ãã¾ã™ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
print(writer.batch_files)

# PosixPath('/folder/5868ba87-743e-4d9e-8fa6-e07b39229425')
```

</TabItem>

<TabItem value='java'>

```java
import java.util.List;

List<List<String>> batchFiles = remoteBulkWriter.getBatchFiles();
System.out.println(batchFiles);

// [["/5868ba87-743e-4d9e-8fa6-e07b39229425/1.parquet"]]
```

</TabItem>
</Tabs>

BulkWriterã¯UUIDã‚’ç”Ÿæˆã—ã€æä¾›ã•ã‚ŒãŸå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«UUIDã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¾ã™ã€‚[æº–å‚™ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã“ã“ã‚’ã‚¯ãƒªãƒƒã‚¯](https://assets.zilliz.com/bulk_writer.zip)ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ãŒå¯èƒ½ãªãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã§ã™:

- ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½“æ ¼ã‚’è¶…ãˆãªã„å ´åˆ

    ```python
    # JSON
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â””â”€â”€ 1.json 
    
    # Parquet
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â””â”€â”€ 1.parquet 
    
    # Numpy
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â”œâ”€â”€ id.npy
    â”‚       â”œâ”€â”€ vector.npy
    â”‚       â”œâ”€â”€ scalar_1.npy
    â”‚       â”œâ”€â”€ scalar_2.npy
    â”‚       â””â”€â”€ $meta.npy 
    ```

    <table>
       <tr>
         <th><p><strong>ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—</strong></p></th>
         <th><p><strong>æœ‰åŠ¹ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹</strong></p></th>
       </tr>
       <tr>
         <td><p><strong>JSON</strong></p></td>
         <td><p><code>s 3://remote_bucket/folder/ãƒ•ã‚©ãƒ«ãƒ€/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s 3://remote_bucket/ãƒ•ã‚©ãƒ«ãƒ€/45ae1139-1d87-4aff-85f5-0039111f9e6b/1.json</code></p></td>
       </tr>
       <tr>
         <td><p><strong>ãƒ‘ãƒ¼ã‚±ãƒƒãƒˆ</strong></p></td>
         <td><p><code>s 3://remote_bucket/folder/ãƒ•ã‚©ãƒ«ãƒ€/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s 3://remote_bucket/folder//1. parquetãƒªãƒ¢ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆ/ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼/45ae1139-1d87-4aff-85f5-0039111f9e6b1.parquet</code></p></td>
       </tr>
       <tr>
         <td><p><strong>NumPy</strong></p></td>
         <td><p><code>s 3://remote_bucket/folder/ãƒ•ã‚©ãƒ«ãƒ€/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s 3://remote_bucket/folder/*. npyãƒªãƒ¢ãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆ/ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼45ae1139-1d87-4aff-85f5-0039111f9e6b.npy</code></p></td>
       </tr>
    </table>

- ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½“æ ¼ã‚’è¶…ãˆã‚‹å ´åˆ

    ```python
    # The following assumes that two segments are generated.
    
    # JSON
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â”œâ”€â”€ 1.json
    â”‚       â””â”€â”€ 2.json 
    
    # Parquet
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â”œâ”€â”€ 1.parquet
    â”‚       â””â”€â”€ 2.parquet 
    
    # Numpy
    â”œâ”€â”€ folder
    â”‚   â””â”€â”€ 45ae1139-1d87-4aff-85f5-0039111f9e6b
    â”‚       â”œâ”€â”€ 1
    â”‚       â”‚   â”œâ”€â”€ id.npy
    â”‚       â”‚   â”œâ”€â”€ vector.npy
    â”‚       â”‚   â”œâ”€â”€ scalar_1.npy
    â”‚       â”‚   â”œâ”€â”€ scalar_2.npy
    â”‚       â”‚   â””â”€â”€ $meta.npy 
    â”‚       â””â”€â”€ 2
    â”‚           â”œâ”€â”€ id.npy
    â”‚           â”œâ”€â”€ vector.npy
    â”‚           â”œâ”€â”€ scalar_1.npy
    â”‚           â”œâ”€â”€ scalar_2.npy
    â”‚           â””â”€â”€ $meta.npy  
    ```

    <table>
       <tr>
         <th><p><strong>ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—</strong></p></th>
         <th><p><strong>æœ‰åŠ¹ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹</strong></p></th>
       </tr>
       <tr>
         <td><p><strong>JSON</strong></p></td>
         <td><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/1.json</code></p></td>
       </tr>
       <tr>
         <td><p><strong>Parquet</strong></p></td>
         <td><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/1.parquet</code></p></td>
       </tr>
       <tr>
         <td><p><strong>NumPy</strong></p></td>
         <td><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/</code></p><p><code>s3://remote_bucket/folder/45ae1139-1d87-4aff-85f5-0039111f9e6b/*.npy</code></p></td>
       </tr>
    </table>

## é–¢é€£ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯{#related-topics}

- [ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ(ã‚³ãƒ³ã‚½ãƒ¼ãƒ«)](./import-data-on-web-ui)

- [ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ(RESTful API)](./import-data-via-restful-api)

- [ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ(SDK)](./import-data-via-sdks)

