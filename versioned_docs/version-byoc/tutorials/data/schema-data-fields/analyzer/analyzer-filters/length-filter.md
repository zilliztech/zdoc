---
title: "Length | BYOC"
slug: /length-filter
sidebar_label: "Length"
beta: PUBLIC
notebook: FALSE
description: "The `length` filter removes tokens that do not meet specified length requirements, allowing you to control the length of tokens retained during text processing. | BYOC"
type: origin
token: MKdvwWBDRi5MMAkkn5PcD1x9nfh
sidebar_position: 6
keywords: 
  - zilliz
  - vector database
  - cloud
  - collection
  - schema
  - analyzer
  - built-in filters
  - length
  - milvus
  - Zilliz
  - milvus vector database
  - milvus db

---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Length

The `length` filter removes tokens that do not meet specified length requirements, allowing you to control the length of tokens retained during text processing.

## Configuration{#configuration}

The `length` filter is a custom filter in Zilliz Cloud, specified by setting `"type": "length"` in the filter configuration. You can configure it as a dictionary within the `analyzer_params` to define length limits.

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
analyzer_params = {
    "tokenizer": "standard",
    "filter":[{
        "type": "length", # Specifies the filter type as length
        "max": 10, # Sets the maximum token length to 10 characters
    }],
}
```

</TabItem>

<TabItem value='java'>

```java
Map<String, Object> analyzerParams = new HashMap<>();
analyzerParams.put("tokenizer", "standard");
analyzerParams.put("filter",
    Collections.singletonList(new HashMap<String, Object>() {{
        put("type", "length");
        put("max", 10);
}}));
```

</TabItem>
</Tabs>

The `length` filter accepts the following configurable parameters.

<table>
   <tr>
     <th><p>Parameter</p></th>
     <th><p>Description</p></th>
   </tr>
   <tr>
     <td><p><code>max</code></p></td>
     <td><p>Sets the maximum token length. Tokens longer than this length are removed.</p></td>
   </tr>
</table>

The `length` filter operates on the terms generated by the tokenizer, so it must be used in combination with a tokenizer. For a list of tokenizers available in Zilliz Cloud, refer to [Tokenizer Reference](./analyzer-tokenizers).

After defining `analyzer_params`, you can apply them to a `VARCHAR` field when defining a collection schema. This allows Zilliz Cloud to process the text in that field using the specified analyzer for efficient tokenization and filtering. For details, refer to [Example use](./analyzer-overview).

## Example output{#example-output}

Hereâ€™s an example of how the `length` filter processes text:

**Example text**:

```python
"The length filter allows control over token length requirements for text processing."
```

**Expected output** (with `max: 10`):

```python
["length", "filter", "allows", "control", "over", "token", "length", "for", "text"]
```

